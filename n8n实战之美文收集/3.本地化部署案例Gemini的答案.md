既然是 **本地化 Docker 部署**（且运行在您的 NAS 上），这比云端部署有一个巨大的优势：**n8n 可以直接读写您的硬盘文件**。您不需要绕道 GitHub API，可以直接操作您的 Obsidian 库文件。

鉴于您是在中国境内使用 NAS（根据您之前的上下文），有两个关键点需要特别配置：**文件路径映射（Volumes）** 和 **网络代理（Proxy）**。

以下是针对您本地 Docker 环境的部署方案：

### 第一步：调整 Docker 容器配置 (核心基础)

要让 n8n 能够“摸到”您的美文库，必须把 NAS 上的 Obsidian 文件夹挂载进容器。同时，为了让 n8n 能连接 OpenAI/Claude 和 Google 搜索，您必须配置代理（考虑到您的网络环境）。

请检查或重建您的 Docker 容器（推荐使用 Docker Compose）：

YAML

```
version: '3.8'

services:
  n8n:
    image: n8nio/n8n
    restart: always
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=your_password
      # 👇 关键点1：配置代理（因为您在国内，必须让n8n能连上OpenAI）
      - HTTP_PROXY=http://192.168.x.x:7890  # 您的Stash/3x-ui局域网代理地址
      - HTTPS_PROXY=http://192.168.x.x:7890
      # 允许读取本地文件（n8n默认处于安全考虑可能限制读取）
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
    volumes:
      - ./n8n_data:/home/node/.n8n
      # 👇 关键点2：把您的 Obsidian 库挂载进去
      # 格式：/NAS上的实际路径:/容器内的路径
      - /volume1/docker/obsidian/workspace:/files/obsidian
```

### 第二步：n8n 节点替换 (从 GitHub 转为 Local File)

由于是本地部署，您不需要 `GitHub` 节点，而是使用 n8n 内置的 **Files (Read/Write)** 节点。

#### 1. 读取总索引 (Step 0 & 5)

- **节点类型**：`Read/Write Files from Disk`
    
- **操作**：Read File
    
- **File Path**：`/files/obsidian/美文总索引.md` (这是容器内的路径)
    
- **Property Name**：`data` (读取为二进制)
    
- ***后续节点***：接一个 `Spreadsheet File` 或者代码节点，把二进制转为文本给 LLM 看。
    

```
- **配置详情 ：**
- 修改了 /vol1/1000/docker/n8n/docker-compose.yml 文件
- 在 volumes 部分添加了映射： ./workspace:/home/node/workspace
- 重启了n8n服务以应用配置
- 验证了挂载点，确认映射成功
使用方法 ：
在n8n的Read/Write Files from Disk节点中，使用 /home/node/.n8n/workspace 作为本地路径，即可访问和操作 /vol1/1000/docker/n8n/workspace 目录下的文件。
验证结果 ：
通过 docker inspect 命令确认，容器内的 /home/node/workspace 已成功映射到本地的 /vol1/1000/docker/n8n/workspace 目录。
```

#### 2. AI 搜索与生成 (Step 1-4)

这部分逻辑不变，依然使用 **AI Agent** 或 **OpenAI/LangChain** 节点。

- 因为您配置了 `HTTP_PROXY`，这些节点应该能正常访问外部 API。
    
- **注意**：如果是 NAS 性能有限，建议不要在本地跑 LLM（Ollama），还是调用 OpenAI/Claude 的 API 比较稳妥，尤其是在处理长文本排版时。
    

#### 3. 写入文章与片段 (Step 4 & 6)

- **节点类型**：`Read/Write Files from Disk`
    
- **操作**：Write File
    
- **File Path**：`/files/obsidian/小学生美文/{{$json.filename}}` (利用表达式动态生成路径)
    
- **File Content**：直接写入 LLM 生成的 Markdown 内容。
    
- **Append 模式**：对于 `{级别}美文精选100篇.md`，记得勾选 "Append" (追加) 选项，而不是覆盖。
    

### 第三步：解决最头疼的“权限问题”

在 NAS 上用 Docker 操作文件，最容易遇到的报错是 `EACCES: permission denied`。

- **原因**：n8n 容器内部通常以 `node` 用户 (uid 1000) 运行，而您的 NAS 文件夹可能属于 `root` 或 `admin`。
    
- **解决方案**：
    
    1. 简单粗暴法：通过 SSH 进入 NAS，给您的美文文件夹赋予宽松权限：
        
        chmod -R 777 /vol1/1000/docker/n8n/workspace
        
    2. **优雅法**：在 Docker Compose 中指定 `user: "1000:1000"` (如果您的 NAS 用户 ID 匹配)，或者使用环境变量 `PUID` / `PGID` (如果 n8n 镜像支持，官方镜像通常建议通过 user 指定)。
        

### 第四步：构建工作流 (Local Version)

这里是一个针对本地部署的简化逻辑流：

1. **Schedule Trigger**: 每天凌晨 4 点。
    
2. **Read File (Total Index)**: 读取 `/files/obsidian/美文总索引.md`。
    
3. **LLM Decision**: 规划今天要收录的题目。
    
4. **Loop**:
    
    - **Agent (Search)**: 联网搜索原文、验证版本 (SerpApi)。
        
    - **Read File (Template)**: 读取 `/files/obsidian/小学生美文/通用模版.md`。
        
    - **LLM (Formatter)**: 填入模版，生成完整 Markdown。
        
    - **Write File (Article)**: 保存为 `/files/obsidian/小学生美文/01.xx.md`。
        
    - **Write File (Snippet)**: 追加片段到精选集。
        
5. **LLM (Updater)**: 生成新的索引内容。
    
6. **Write File (Index)**: 覆盖更新 `/files/obsidian/美文总索引.md`。
    

### 💡 给您的特别建议

鉴于您之前提到在学习 **Python** 且有 **"零基础"** 的背景（Fact 21），其实您可以用 n8n 的 **Python Code Node** 来处理一些复杂的文本逻辑（比如正则匹配文件名、计算字数），这比单纯写 Prompt 更精准，也是一个很好的练习机会。

现在的下一步：

您需要我为您写一段 docker-compose.yml 配置文件，还是先为您写一段用于 n8n Python 节点 的代码（用来处理“三步验证法”中的文本比对逻辑）？

这是一个非常适合您练手的场景。这段 Python 代码将作为 n8n 流程中的 **“逻辑过滤器”**，用于执行《美文收集标准流程》中 **Step 3（搜索原文）** 的核心逻辑——**三步验证法**。

它的作用是：接收上一步（AI Agent 或 搜索节点）找到的文章内容，用代码“冷酷”地进行检查，防止 AI “幻觉”或者通过了删改版。

### 📍 节点位置

- **前置节点**：AI Agent (Output: `found_content`, `url`) 或 HTTP Request (获取到的网页内容)。
    
- **当前节点**：Python Code。
    
- **后置节点**：If (判断 `is_valid` 是否为 True)。
    

### 🐍 Python 代码 (复制到 n8n 节点中)

Python

```
import re

# ================= 配置区 =================
# 您可以在这里根据不同级别调整参数
MIN_LENGTH = 300       # 最小字数限制（高中/成人建议300+，小学150+）
FORBIDDEN_KEYWORDS = [ # 这些词如果出现，说明很可能是教材删改版
    "有删改", "选自", "课文版", "教材版", 
    "节选", "改为", "删去", "改写"
]
# =========================================

# 获取上一个节点的输出数据
# n8n 会自动把输入项放在 _input.all() 中
items = _input.all()
output_items = []

for item in items:
    # 假设上一个节点输出的字段叫 "content" 和 "title"
    # 如果您的字段名不同，请在这里修改，例如 item.json['text']
    content = item.json.get('content', '')
    title = item.json.get('title', '未知标题')
    
    # 初始化验证结果
    verification_log = []
    is_valid = True
    reason = "验证通过"

    # --- 🔍 验证第一步：字数检查 (Word Count Check) ---
    # 去掉所有空格和换行符，计算纯中文字符数
    clean_content = re.sub(r'\s+', '', content)
    current_length = len(clean_content)
    
    if current_length < MIN_LENGTH:
        is_valid = False
        reason = f"字数不足 (当前: {current_length}, 要求: {MIN_LENGTH})"
        verification_log.append("❌ 字数检查失败")
    else:
        verification_log.append(f"✅ 字数检查通过 ({current_length}字)")

    # --- 🔍 验证第二步：敏感词检查 (Modification Check) ---
    # 检查文章开头或结尾是否包含“有删改”等字样
    # 为了防止误杀（比如文章里正好提到这几个字），我们主要检查前200字和后200字
    check_range = content[:200] + content[-200:]
    
    found_forbidden = []
    for keyword in FORBIDDEN_KEYWORDS:
        if keyword in check_range:
            found_forbidden.append(keyword)
    
    if found_forbidden:
        is_valid = False
        # 如果发现了敏感词，标记为失败
        reason = f"疑似删改版 (发现关键词: {', '.join(found_forbidden)})"
        verification_log.append(f"❌ 版本纯净度检查失败: {reason}")
    else:
        verification_log.append("✅ 版本纯净度检查通过")

    # --- 🔍 验证第三步：格式完整性 (简单检查) ---
    # 比如检查是否包含过多的 HTML 标签残留，或者乱码
    if len(re.findall(r'<[^>]+>', content)) > 10:
        is_valid = False
        reason = "包含过多HTML标签，清洗不干净"
        verification_log.append("❌ 格式检查失败")
    
    # --- 📤 构造输出数据 ---
    # 我们把验证结果写入新的字段，传给下一个节点
    output_item = item.json.copy() # 复制原有数据
    output_item['verification_result'] = {
        'is_valid': is_valid,           # True/False，给 If 节点用
        'reason': reason,               # 失败原因
        'word_count': current_length,   # 字数
        'log': " | ".join(verification_log) # 完整的验证日志
    }
    
    output_items.append(output_item)

# 返回处理后的数据给 n8n
return output_items
```

### 🎓 代码解析 (配合您的 Python 学习)

1. _input.all():
    
    这是 n8n 特有的写法。它获取流入该节点的所有数据项（JSON格式）。
    
2. re 模块:
    
    这是 Python 的 正则表达式 库。
    
    - `re.sub(r'\s+', '', content)`: 这行代码的作用是把文章里所有的空格、换行、Tab全部“吃掉”，剩下的才是纯汉字，用来统计字数最准。
        
3. **敏感词逻辑**:
    
    - `check_range = content[:200] + content[-200:]`: 这是一个小技巧。通常“本文选自...有删改”这种说明，要么在文章最开头，要么在最结尾。我们只检查这两个区域，避免文章正文里刚好有个“改写”这个词导致误判。
        
4. **数据流转**:
    
    - 我们没有直接修改原始数据，而是创建了 `output_item`，并添加了一个 `verification_result` 字典。这样您的下一个节点（比如 If Node）就可以直接引用 `{{ $json.verification_result.is_valid }}` 来决定走哪条路。
        

### 🔧 如何在 n8n 中调试它？

1. Mock Data (模拟数据):
    
    在 Python 节点前暂时加一个 Edit Fields 节点，手动填入一段测试 JSON：
    
    JSON
    
    ```
    {
      "title": "落花生",
      "content": "落花生...（这里粘贴一段只有100字的删改版内容）...本文有删改。"
    }
    ```
    
2. 运行 Python 节点:
    
    点击 Python 节点的 "Execute Node"。
    
3. 查看 Output:
    
    您应该能看到 is_valid 变成了 false，并且 reason 里会提示 "疑似删改版" 或 "字数不足"。
    

### 🚀 下一步配置

将这个节点连接到一个 **If Node**：

- **Condition**: Boolean
    
- **Value 1**: `{{ $json.verification_result.is_valid }}`
    
- **Equal to**: `true`
    

True 分支 -> 连接到 Step 4 (格式化文章)

False 分支 -> 连接到 AI Agent (让它重试，或者换一篇)